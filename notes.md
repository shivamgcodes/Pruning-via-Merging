# models

## meta 
 VITs - currently have three models from them ViTs, these are MAE with losses available
 DEITS - then they also have a school of deit s , these are img classification models, sooo again, easy to eval
 DINOv2 (maybe exclude the giant) and for feature extraction too and img classification
## google 
 VIT - they also have their own school of ViTs
 https://github.com/google-research/vision_transformer?tab=readme-ov-file#available-vit-models

 LIT - yet to check LiT

 SIgLIP - zero shot image classification ig (check krta hun kya hai)

 MLP mixer (idk most probably not)
## tnt
 TNT - https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/tnt_pytorch
 classification (apparently)

## microsoft
 swin - image classification 
 Beit 

## nvdia

NVILA -  uses SiglipVisionModel 
VILA - uses SiglipVisionModel, and InternVisionModel
cosmosnemotron - uses Siglip-400M

segmentation models
SegFormer-B0: 3.7M parameters
SegFormer-B1: 13.7M parameters
SegFormer-B2: 27.5M parameters
SegFormer-B3: 47.3M parameters
SegFormer-B4: 64.1M parameters
SegFormer-B5: 84.7M parameters

## EVA 2
can do .. idk i am tired of listing models now
https://huggingface.co/Yuxin-CV/EVA-02/blob/main/eva02/det/eva02_L_coco_det_sys_o365.pth

## clip
https://huggingface.co/openai/clip-vit-large-patch14-336

## IBM
 crossvit (classification)
------------------------------
image gen

##nvidia
 sana - text to image Linear diffusion transformer .. lol wtf idk what to do of that
